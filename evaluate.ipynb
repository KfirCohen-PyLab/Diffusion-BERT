{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiffusionBERT Evaluation\n",
    "\n",
    "This notebook implements the evaluation pipeline for DiffusionBERT with the updated model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository and setup paths\n",
    "!git clone https://github.com/KfirCohen-PyLab/Diffusion-BERT.git\n",
    "%cd /content/Diffusion-BERT\n",
    "!pwd\n",
    "\n",
    "# Create necessary directories\n",
    "!mkdir -p word_freq\n",
    "!mkdir -p checkpoints\n",
    "\n",
    "# Copy required files from Drive\n",
    "!cp '/content/drive/MyDrive/DiffusionBERT/word_freq.pt' './word_freq/bert-base-uncased_lm1b.pt'\n",
    "!cp '/content/drive/MyDrive/ML_Project_Sem6/diffusion_bert_lm1b_checkpoint_e0_s26999.pt' './checkpoints/diffusion_bert_lm1b_final.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add current directory to Python path\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import diffusion\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from models.modeling_diffusion_bert_checkpoint import DiffusionBertForMaskedLM\n",
    "from sample import Categorical, WholeWordMasking\n",
    "import time\n",
    "from fastNLP import logger\n",
    "from tqdm import tqdm\n",
    "from dataloader import DiffusionLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "model_ckpt_path = './checkpoints/diffusion_bert_lm1b_final.pt'\n",
    "model_name = 'bert-base-uncased'\n",
    "predict_x0 = True\n",
    "sample_strategy = 'Categorical'\n",
    "num_steps = 2048\n",
    "kind = 'word_freq'\n",
    "word_freq_lambda = 0.3\n",
    "schedule = 'mutual'\n",
    "eval_step_size = 16\n",
    "timestep = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup\n",
    "model_cls = DiffusionBertForMaskedLM\n",
    "cfg_cls = BertConfig\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if sample_strategy == 'Categorical':\n",
    "    sample_cls = Categorical()\n",
    "elif sample_strategy == 'wwm':\n",
    "    sample_cls = WholeWordMasking(tokenizer)\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffusion setup\n",
    "if kind == 'word_freq':\n",
    "    import diffusion_word_freq as diffusion\n",
    "    word_freq = torch.load(f'./word_freq/{model_name}_lm1b.pt', map_location=device)\n",
    "    def word_freq_preprocess_fn(wf):\n",
    "        wf = wf + 1\n",
    "        wf = wf.log()\n",
    "        wf = wf / wf.max()\n",
    "        return wf\n",
    "\n",
    "    word_freq = word_freq_preprocess_fn(word_freq)\n",
    "    diffusion_schedule = diffusion.create_discrete_diffusion_schedule(schedule, num_steps=num_steps)\n",
    "    diffusion_instance = diffusion.MaskDiffusion(\n",
    "        dim=tokenizer.vocab_size,\n",
    "        schedule=diffusion_schedule,\n",
    "        tokenizer=tokenizer,\n",
    "        sample_cls=sample_cls,\n",
    "        word_freq=word_freq,\n",
    "        word_freq_lambda=word_freq_lambda,\n",
    "        device=device\n",
    "    )\n",
    "elif kind == 'base':\n",
    "    import diffusion\n",
    "    diffusion_schedule = diffusion.create_discrete_diffusion_schedule(schedule, num_steps=num_steps)\n",
    "    diffusion_instance = diffusion.MaskDiffusion(\n",
    "        dim=tokenizer.vocab_size,\n",
    "        schedule=diffusion_schedule,\n",
    "        tokenizer=tokenizer,\n",
    "        sample_cls=sample_cls,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "cfg = cfg_cls.from_pretrained(model_name)\n",
    "cfg.overall_timestep = diffusion_instance.num_steps\n",
    "\n",
    "model = model_cls(cfg).to(device)\n",
    "# Load state dict with CPU mapping first, then move to GPU\n",
    "state_dict = torch.load(model_ckpt_path, map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Create tensors on the correct device\n",
    "cls = torch.full((1, 1), fill_value=tokenizer.cls_token_id, device=device)\n",
    "sep = torch.full((1, 1), fill_value=tokenizer.sep_token_id, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise function setup\n",
    "att_ones = torch.ones((1, 1), device=device)\n",
    "att_zeros = torch.zeros((1, 1), device=device)\n",
    "\n",
    "def denoise_fn(targets, timestep, attention_mask):\n",
    "    assert len(targets.size()) == 2  # bsz * seqlen\n",
    "    bsz = targets.size(0)\n",
    "    targets = torch.cat((cls.repeat(bsz, 1), targets, sep.repeat(bsz, 1)), dim=1)\n",
    "    attention_mask = torch.cat((att_ones.repeat(bsz, 1), attention_mask, att_zeros.repeat(bsz, 1)), dim=1)\n",
    "    return model(\n",
    "        input_ids=targets,\n",
    "        attention_mask=attention_mask,\n",
    "        timestep=timestep\n",
    "    )['logits'][:, 1:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing functions\n",
    "def process_fn_in_collate(wf):\n",
    "    return wf - wf.mean()\n",
    "\n",
    "def collate_fn(batch_input):\n",
    "    input_ids = [torch.tensor(d['input_ids'], device=device) for d in batch_input]\n",
    "    attention_mask = [torch.tensor(d['attention_mask'], device=device) for d in batch_input]\n",
    "    word_freq_logits = [process_fn_in_collate(word_freq.gather(0, torch.tensor(d['input_ids'], device=device))) for d in batch_input]\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True)\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True)\n",
    "    word_freq_logits = pad_sequence(word_freq_logits, batch_first=True)\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'word_freq_logits': word_freq_logits\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "elbo = 0.\n",
    "count = 0\n",
    "\n",
    "test_data = DiffusionLoader(tokenizer=tokenizer).my_load(task_name='lm1b', splits=['test'])[0]\n",
    "_, test_data = test_data.train_test_split(test_size=5e-2).values()\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        batch_dev_metrics = diffusion.discrete_diffusion_elbo(\n",
    "            batch['input_ids'],  # Already on GPU from collate_fn\n",
    "            denoise_fn=denoise_fn,\n",
    "            diffusion=diffusion_instance,\n",
    "            target_mask=batch['attention_mask'],  # Already on GPU from collate_fn\n",
    "            word_freq_logits=batch['word_freq_logits'],  # Already on GPU from collate_fn\n",
    "            normalize_without_padding=True,\n",
    "            eval_step_size=eval_step_size,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        if not torch.isnan(batch_dev_metrics['elbo']):\n",
    "            logger.info(batch_dev_metrics['elbo'])\n",
    "            elbo += batch_dev_metrics['elbo']\n",
    "            count += 1\n",
    "\n",
    "print(f\"Final ELBO: {elbo / (64. * count)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}