"""
CPU-Optimized Classroom Demo for Diffusion BERT
Designed for laptops without GPU - optimized for CPU performance
"""

import torch
import argparse
from transformers import BertTokenizer, BertConfig
from models.modeling_bert import BertForMaskedLM
import os
import random
import time

class CPUClassroomDemo:
    def __init__(self, checkpoint_path):
        """Initialize demo for CPU-only execution"""
        self.device = torch.device("cpu")
        print("üíª CPU-OPTIMIZED DEMONSTRATION")
        print("üîß Optimized for laptop presentations without GPU")
        print()
        self.load_model(checkpoint_path)
        
    def load_model(self, checkpoint_path):
        """Load trained model optimized for CPU"""
        print("üéì Loading Diffusion BERT model (CPU mode)...")
        print(f"üìÇ Checkpoint: {os.path.basename(checkpoint_path)}")
        print("‚è≥ Please wait 30-60 seconds for CPU loading...")
        
        start_time = time.time()
        
        # Load checkpoint
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        # Initialize model with CPU optimizations
        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
        cfg = BertConfig.from_pretrained('bert-base-uncased')
        cfg.overall_timestep = 32
        
        self.model = BertForMaskedLM(cfg)
        self.model.load_state_dict(checkpoint['model'])
        self.model.eval()
        
        # CPU optimization
        torch.set_num_threads(4)  # Optimize for typical laptop CPUs
        
        load_time = time.time() - start_time
        print(f"‚úÖ Model loaded successfully in {load_time:.1f} seconds!\n")
    
    def demonstrate_capability(self, text, mask_ratio=0.3, show_process=True):
        """Demonstrate single example with clear explanation (CPU optimized)"""
        if show_process:
            print(f"üéØ DEMONSTRATION: Mask & Reconstruct")
            print(f"üìù Original sentence: '{text}'")
            print(f"üé≠ Masking {mask_ratio:.0%} of tokens randomly...")
            time.sleep(0.5)  # Shorter pause for CPU
        
        start_inference = time.time()
        
        # Tokenize input
        tokens = self.tokenizer.encode(text, return_tensors='pt', max_length=64, truncation=True)
        
        # Apply random masking
        masked_tokens = self._apply_random_mask(tokens.clone(), mask_ratio)
        masked_text = self.tokenizer.decode(masked_tokens[0], skip_special_tokens=True)
        
        if show_process:
            print(f"üîç After masking: '{masked_text}'")
            print("ü§ñ Running BERT reconstruction (CPU)...")
        
        # BERT reconstruction
        reconstructed_tokens = self._bert_denoise(masked_tokens)
        reconstructed_text = self.tokenizer.decode(reconstructed_tokens[0], skip_special_tokens=True)
        
        inference_time = time.time() - start_inference
        
        # Calculate similarity
        similarity = self._calculate_similarity(text, reconstructed_text)
        
        if show_process:
            print(f"‚ú® Reconstructed: '{reconstructed_text}'")
            print(f"üìä Accuracy: {similarity:.1%} {'üéâ Excellent!' if similarity > 0.8 else 'üëç Good!' if similarity > 0.6 else '‚ö†Ô∏è Fair'}")
            print(f"‚ö° Processing time: {inference_time:.2f} seconds")
            print("-" * 60)
        
        return {
            'original': text,
            'masked': masked_text,
            'reconstructed': reconstructed_text,
            'accuracy': similarity,
            'processing_time': inference_time
        }
    
    def run_laptop_demo(self):
        """Optimized demo for laptop presentations"""
        print("üéì DIFFUSION BERT - LAPTOP DEMONSTRATION")
        print("=" * 60)
        print("üìö What we're demonstrating:")
        print("   ‚Ä¢ AI model trained for text reconstruction")
        print("   ‚Ä¢ Randomly mask words in sentences")
        print("   ‚Ä¢ Model reconstructs missing words using context")
        print("   ‚Ä¢ Shows language understanding capabilities")
        print("=" * 60)
        print("üíª Running on CPU - optimized for laptops")
        print()
        
        # Carefully selected examples that work well
        demo_examples = [
            "Artificial intelligence is transforming modern technology",
            "Students learn programming through practice and examples", 
            "Machine learning models process large amounts of data",
            "Computer science involves algorithms and problem solving"
        ]
        
        total_accuracy = 0
        total_time = 0
        
        for i, example in enumerate(demo_examples, 1):
            print(f"üìã EXAMPLE {i}/{len(demo_examples)}")
            result = self.demonstrate_capability(example, mask_ratio=0.3)
            total_accuracy += result['accuracy']
            total_time += result['processing_time']
            
            if i < len(demo_examples):
                input("\n‚è∏Ô∏è  Press Enter to continue to next example...")
                print()
        
        # Summary optimized for classroom
        avg_accuracy = total_accuracy / len(demo_examples)
        avg_time = total_time / len(demo_examples)
        
        print(f"üèÜ DEMONSTRATION SUMMARY")
        print(f"   üìä Average Reconstruction Accuracy: {avg_accuracy:.1%}")
        print(f"   ‚ö° Average Processing Time: {avg_time:.2f} seconds")
        print(f"   üéØ Model Performance: {'Excellent' if avg_accuracy > 0.8 else 'Good' if avg_accuracy > 0.6 else 'Needs Improvement'}")
        print(f"   üí° This demonstrates successful language model training!")
        print(f"   üíª All processing done on CPU (no GPU required)")
    
    def quick_interactive_demo(self):
        """Quick interactive session for audience"""
        print("\nüéÆ QUICK INTERACTIVE TEST")
        print("=" * 40)
        print("Let's test a few more examples quickly!")
        print("(Keep them under 10 words for best CPU performance)")
        print()
        
        max_attempts = 3
        attempt = 0
        
        while attempt < max_attempts:
            try:
                user_input = input(f"üìù Enter sentence {attempt+1}/{max_attempts} (or 'done' to finish): ").strip()
                
                if user_input.lower() in ['done', 'quit', 'exit', 'stop']:
                    break
                
                if not user_input:
                    continue
                
                if len(user_input.split()) > 12:
                    print("‚ö†Ô∏è For best CPU performance, try shorter sentences (under 12 words)")
                    continue
                
                print()
                result = self.demonstrate_capability(user_input)
                print()
                attempt += 1
                
            except KeyboardInterrupt:
                print("\nüéâ Thank you! End of interactive demo.")
                break
        
        print("üéâ Interactive demonstration complete!")
    
    def show_training_methodology(self):
        """Show the training approach used"""
        print("\nüìö TRAINING METHODOLOGY OVERVIEW")
        print("=" * 50)
        print("üéØ Model Architecture: BERT-base (110M parameters)")
        print("üîÑ Training Approach: Diffusion-based denoising")
        print("üìä Dataset: QQP (Quora Question Pairs)")
        print("üé≠ Training Task: Mask ‚Üí Reconstruct")
        print("‚ö° Inference: CPU-optimized for demonstrations")
        print()
        
        # Show what the model learned
        print("üí° What the model learned:")
        print("   ‚Ä¢ Language patterns and grammar")
        print("   ‚Ä¢ Word relationships and context")
        print("   ‚Ä¢ Semantic meaning preservation")
        print("   ‚Ä¢ Robust reconstruction abilities")
    
    def _apply_random_mask(self, tokens, mask_ratio):
        """Apply random masking to tokens"""
        seq_len = tokens.size(1)
        n_mask = max(1, int(mask_ratio * seq_len))
        
        maskable_positions = list(range(1, seq_len - 1))
        
        if len(maskable_positions) >= n_mask:
            mask_positions = random.sample(maskable_positions, n_mask)
            for pos in mask_positions:
                tokens[0, pos] = self.tokenizer.mask_token_id
        
        return tokens
    
    def _bert_denoise(self, masked_tokens):
        """CPU-optimized BERT denoising"""
        with torch.no_grad():
            # CPU optimization: disable gradients completely
            attention_mask = (masked_tokens != self.tokenizer.pad_token_id).long()
            
            # Simplified inference for CPU
            outputs = self.model(input_ids=masked_tokens, attention_mask=attention_mask)
            logits = outputs.logits
            
            mask_positions = (masked_tokens == self.tokenizer.mask_token_id)
            
            if not mask_positions.any():
                return masked_tokens
            
            reconstructed_tokens = masked_tokens.clone()
            
            # Simplified sampling for CPU performance
            predicted_tokens = logits.argmax(dim=-1)
            reconstructed_tokens = torch.where(mask_positions, predicted_tokens, masked_tokens)
            
            return reconstructed_tokens
    
    def _calculate_similarity(self, text1, text2):
        """Calculate word-level similarity"""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        return len(words1 & words2) / max(len(words1), 1)

def main():
    parser = argparse.ArgumentParser(description="CPU Classroom Demo of Diffusion BERT")
    parser.add_argument("--checkpoint", type=str, required=True, help="Path to model checkpoint")
    parser.add_argument("--mode", type=str, default="full", 
                       choices=["full", "demo", "interactive", "methodology"], 
                       help="Demo mode")
    
    args = parser.parse_args()
    
    print("üíª DIFFUSION BERT - LAPTOP CLASSROOM DEMO")
    print("üîß CPU-optimized for presentations without GPU")
    print("=" * 50)
    print()
    
    # Initialize demo
    try:
        demo = CPUClassroomDemo(args.checkpoint)
    except Exception as e:
        print(f"‚ùå Failed to load model: {e}")
        print("üí° Make sure the checkpoint path is correct")
        return
    
    # Run demonstration based on mode
    if args.mode == "full":
        demo.show_training_methodology()
        demo.run_laptop_demo()
        demo.quick_interactive_demo()
    elif args.mode == "demo":
        demo.run_laptop_demo()
    elif args.mode == "interactive":
        demo.quick_interactive_demo()
    elif args.mode == "methodology":
        demo.show_training_methodology()
    
    print("\nüéì Thank you for attending the demonstration!")
    print("üíª All processing completed on CPU")

if __name__ == "__main__":
    main() 